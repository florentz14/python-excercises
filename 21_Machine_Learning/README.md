# 21 - Machine Learning

Comprehensive Python exercises covering fundamental Machine Learning concepts using **NumPy**, **SciPy**, **scikit-learn**, and **Matplotlib**.

## Prerequisites

```bash
pip install numpy scipy scikit-learn matplotlib pandas
```

## Files (23 programs)

| #  | File | Topic |
|----|------|-------|
| 01 | `01_getting_started.py` | ML introduction, workflow, data types, library check |
| 02 | `02_mean_median_mode.py` | Mean, median, mode, weighted mean, skewed data |
| 03 | `03_standard_deviation.py` | Std dev, variance, 68-95-99.7 rule, population vs sample |
| 04 | `04_percentile.py` | Percentiles, quartiles, IQR, outlier detection |
| 05 | `05_data_distribution.py` | Uniform, normal, skewed distributions, histograms |
| 06 | `06_normal_data_distribution.py` | Bell curve, Z-score, normality testing, Shapiro-Wilk |
| 07 | `07_scatter_plot.py` | Scatter plots, correlation, trend lines, color maps |
| 08 | `08_linear_regression.py` | Linear regression, R², prediction, residuals |
| 09 | `09_polynomial_regression.py` | Polynomial fitting, overfitting, degree comparison |
| 10 | `10_multiple_regression.py` | Multiple features, feature importance, evaluation |
| 11 | `11_scale.py` | StandardScaler, MinMaxScaler, RobustScaler, impact on models |
| 12 | `12_train_test.py` | Train/test split, stratified split, overfitting detection |
| 13 | `13_decision_tree.py` | Classification & regression trees, feature importance, visualization |
| 14 | `14_confusion_matrix.py` | TP/TN/FP/FN, precision, recall, F1, multi-class |
| 15 | `15_hierarchical_clustering.py` | Dendrograms, agglomerative clustering, linkage methods |
| 16 | `16_logistic_regression.py` | Sigmoid, binary/multi-class, decision boundary, regularization |
| 17 | `17_grid_search.py` | GridSearchCV, RandomizedSearchCV, hyperparameter tuning |
| 18 | `18_categorical_data.py` | Label encoding, one-hot encoding, ordinal encoding, pipelines |
| 19 | `19_kmeans.py` | K-Means clustering, elbow method, silhouette score |
| 20 | `20_bootstrap_aggregation.py` | Bagging, Random Forest, OOB score, ensemble methods |
| 21 | `21_cross_validation.py` | K-Fold, stratified, LOO, time series CV, model comparison |
| 22 | `22_auc_roc_curve.py` | ROC curve, AUC, precision-recall, threshold analysis |
| 23 | `23_knn.py` | K-Nearest Neighbors, optimal K, distance metrics, weighted KNN |

## Topics Covered

### Statistics Fundamentals (01-06)
- Central tendency (mean, median, mode)
- Dispersion (standard deviation, variance)
- Percentiles, quartiles, IQR
- Data distributions (normal, uniform, skewed)

### Regression (07-10)
- Scatter plots and correlation
- Linear, polynomial, and multiple regression
- R² score, RMSE, residual analysis

### Preprocessing (11, 18)
- Feature scaling (standardization, normalization)
- Categorical encoding (label, one-hot, ordinal)

### Model Evaluation (12, 14, 21, 22)
- Train/test split and cross-validation
- Confusion matrix and classification metrics
- ROC-AUC curves and precision-recall

### Classification Algorithms (13, 16, 23)
- Decision Trees
- Logistic Regression
- K-Nearest Neighbors (KNN)

### Clustering (15, 19)
- K-Means clustering
- Hierarchical clustering

### Advanced Techniques (17, 20)
- Hyperparameter tuning (Grid Search)
- Ensemble methods (Bootstrap Aggregation, Random Forest)
